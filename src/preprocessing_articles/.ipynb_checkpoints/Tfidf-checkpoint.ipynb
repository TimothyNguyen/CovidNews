{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Common Phrases with tfidf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `max_df=0.8` means exclude phrases that are in 80% of the documents or more (similar to stop words, these are unlikely to be informative since they are so common)\n",
    "\n",
    "* `min_df=50` means that the word must occur at least 50 times in the corpus to be included in analysis (I used 50 because the research paper I mentioned did too, though you may experiment with different cutoffs)\n",
    "\n",
    "* `ngram_range=(1,2)` means includes one-word and two-word phrases (you could easily set it to `(1,3)` to also include trigrams / three-word phrases\n",
    "binary=True means to only count if a word occurs at all in a given document (i.e. 0 or 1), rather than counting exactly how many times it occurs (i.e. 0 or 1 or 2 or 3 or…)\n",
    "\n",
    "* `stop_words=nltk_stop_words` just plugs in the NLTK stop word list set up in the previous line, so that words such as “of” and “to” are not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop_words = stopwords.words('english')\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=50,\n",
    "    ngram_range = (1,5),\n",
    "    binary=True,\n",
    "    stop_words=nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from progressbar import progressbar\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "#import pdb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>twitter</th>\n",
       "      <th>party</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>SenSherrodBrown</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>This year, #WorkersMemorialDay is particularly...</td>\n",
       "      <td>2020-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>SenSherrodBrown</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Without the #ACA, health insurers could discri...</td>\n",
       "      <td>2020-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>SenSherrodBrown</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Just voted to send more than 15 million in eme...</td>\n",
       "      <td>2020-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>SenSherrodBrown</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Mitch McConnell has wasted four days in the mi...</td>\n",
       "      <td>2020-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>SenSherrodBrown</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>TUNE IN: At 12:25 PM, I'm going Live with my f...</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64327</th>\n",
       "      <td>64327</td>\n",
       "      <td>Kelly Loeffler</td>\n",
       "      <td>SenatorLoeffler</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Families in the USA - a pillar of my USA RISE ...</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64328</th>\n",
       "      <td>64328</td>\n",
       "      <td>Kelly Loeffler</td>\n",
       "      <td>SenatorLoeffler</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Two weeks ago, I spoke on the Senate floor con...</td>\n",
       "      <td>2020-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64329</th>\n",
       "      <td>64329</td>\n",
       "      <td>Kelly Loeffler</td>\n",
       "      <td>SenatorLoeffler</td>\n",
       "      <td>Republican</td>\n",
       "      <td>I also hosted a statewide call w/@GACities &amp;am...</td>\n",
       "      <td>2020-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64330</th>\n",
       "      <td>64330</td>\n",
       "      <td>Kelly Loeffler</td>\n",
       "      <td>SenatorLoeffler</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Outstanding work happening in Augusta to take ...</td>\n",
       "      <td>2020-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64331</th>\n",
       "      <td>64331</td>\n",
       "      <td>Kelly Loeffler</td>\n",
       "      <td>SenatorLoeffler</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Great call with the folks of @NCottonCouncil &amp;...</td>\n",
       "      <td>2020-07-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64332 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            name          twitter       party  \\\n",
       "0               0   Sherrod Brown  SenSherrodBrown    Democrat   \n",
       "1               1   Sherrod Brown  SenSherrodBrown    Democrat   \n",
       "2               2   Sherrod Brown  SenSherrodBrown    Democrat   \n",
       "3               3   Sherrod Brown  SenSherrodBrown    Democrat   \n",
       "4               4   Sherrod Brown  SenSherrodBrown    Democrat   \n",
       "...           ...             ...              ...         ...   \n",
       "64327       64327  Kelly Loeffler  SenatorLoeffler  Republican   \n",
       "64328       64328  Kelly Loeffler  SenatorLoeffler  Republican   \n",
       "64329       64329  Kelly Loeffler  SenatorLoeffler  Republican   \n",
       "64330       64330  Kelly Loeffler  SenatorLoeffler  Republican   \n",
       "64331       64331  Kelly Loeffler  SenatorLoeffler  Republican   \n",
       "\n",
       "                                                   tweet tweet_published  \n",
       "0      This year, #WorkersMemorialDay is particularly...      2020-04-28  \n",
       "1      Without the #ACA, health insurers could discri...      2020-03-23  \n",
       "2      Just voted to send more than 15 million in eme...      2020-03-05  \n",
       "3      Mitch McConnell has wasted four days in the mi...      2020-03-17  \n",
       "4      TUNE IN: At 12:25 PM, I'm going Live with my f...      2020-05-21  \n",
       "...                                                  ...             ...  \n",
       "64327  Families in the USA - a pillar of my USA RISE ...      2020-05-18  \n",
       "64328  Two weeks ago, I spoke on the Senate floor con...      2020-03-19  \n",
       "64329  I also hosted a statewide call w/@GACities &am...      2020-03-17  \n",
       "64330  Outstanding work happening in Augusta to take ...      2020-04-23  \n",
       "64331  Great call with the folks of @NCottonCouncil &...      2020-07-13  \n",
       "\n",
       "[64332 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('tweets.csv')\n",
    "# df.at[df.twitter =='SenSanders', 'party'] = 'Democrat' # for ideological purposes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.8, max_features=None, min_df=50,\n",
       "                ngram_range=(1, 5), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fitting...\")\n",
    "tf_vectorizer.fit(df.tweet.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = tf_vectorizer.fit_transform(df.tweet.tolist())\n",
    "phrases_df = pd.DataFrame(data=tf_vectorizer.get_feature_names(),columns=['phrase'])\n",
    "phrases_df['total_occurrences']=term_frequencies.sum(axis=0).T\n",
    "ans = phrases_df.sort_values(by='total_occurrences',ascending=False).head(100)\n",
    "ans.to_csv('top_20_overall.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>total_occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>22908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>covid19</td>\n",
       "      <td>21500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>15854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>covid</td>\n",
       "      <td>13870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>19</td>\n",
       "      <td>13641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>coronavirus pandemic</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>masks</td>\n",
       "      <td>2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>first</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>medical</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phrase  total_occurrences\n",
       "1075           coronavirus              22908\n",
       "1229               covid19              21500\n",
       "3694              pandemic              15854\n",
       "1200                 covid              13870\n",
       "41                      19              13641\n",
       "...                    ...                ...\n",
       "1116  coronavirus pandemic               2204\n",
       "3210                 masks               2201\n",
       "1993                 first               2194\n",
       "3250               medical               2185\n",
       "3650              outbreak               2184\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Measuring Politically Polarized Phrases\n",
    "First things first, we will need to split up the Democrat-authored and Republican-authored texts, and then get their term frequency matrices. The pandas dataframe makes this pretty easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_tfs = tf_vectorizer.transform(df[df.party=='Democrat'].tweet.tolist())\n",
    "rep_tfs = tf_vectorizer.transform(df[df.party=='Republican'].tweet.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42820 Dem docs, 21234 Rep docs\n"
     ]
    }
   ],
   "source": [
    "n_dem_docs = dem_tfs.shape[0]\n",
    "n_rep_docs = rep_tfs.shape[0]\n",
    "print(\"{} Dem docs, {} Rep docs\".format(n_dem_docs, n_rep_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dem_tfs = dem_tfs.sum(axis=0)\n",
    "total_rep_tfs = rep_tfs.sum(axis=0)\n",
    "total_tfs = total_dem_tfs + total_rep_tfs\n",
    "p_dem = total_dem_tfs / n_dem_docs\n",
    "p_rep = total_rep_tfs / n_rep_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the juicy part: figuring out which phrases are politically charged. Here is the part of the paper that explains the method for this (the key formula is highlighted):\n",
    "\n",
    "\n",
    "Next, we extracted all unigrams and bigrams from the cleaned corpus and scored them. We computed the probability of each unigram and bigrams g appearing in Republican and Democrat-authored text as PrR(g) and PrD(g). We then compute the partisan bias y of each g as \n",
    "\n",
    "y(g) = (PrR(g) - PrD(g)) / (PrR(g) + PrD(g))\n",
    "\n",
    "y scores range from [-1, 1], with 1(-1) indicating that a phrase is used exclusively by Republicans(Democrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = (p_rep - p_dem) / (p_rep + p_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_df['bias_score'] = bias.T\n",
    "phrases_df['p_dem'] = p_dem.T\n",
    "phrases_df['p_rep'] = p_rep.T\n",
    "phrases_df['n_dem'] = total_dem_tfs.T\n",
    "phrases_df['n_rep'] = total_rep_tfs.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting senators...\n"
     ]
    }
   ],
   "source": [
    "print('Counting senators...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_df.sort_values(by='total_occurrences',ascending=False).to_csv('all_phrases.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Democratic...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>total_occurrences</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>p_dem</th>\n",
       "      <th>p_rep</th>\n",
       "      <th>n_dem</th>\n",
       "      <th>n_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>ny19</td>\n",
       "      <td>57</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>staters</td>\n",
       "      <td>122</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>away health</td>\n",
       "      <td>67</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>az01</td>\n",
       "      <td>216</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>facebook com events</td>\n",
       "      <td>75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phrase  total_occurrences  bias_score     p_dem  p_rep  \\\n",
       "3578                 ny19                 57        -1.0  0.001331    0.0   \n",
       "4795              staters                122        -1.0  0.002849    0.0   \n",
       "541           away health                 67        -1.0  0.001565    0.0   \n",
       "544                  az01                216        -1.0  0.005044    0.0   \n",
       "1838  facebook com events                 75        -1.0  0.001752    0.0   \n",
       "\n",
       "      n_dem  n_rep  \n",
       "3578     57      0  \n",
       "4795    122      0  \n",
       "541      67      0  \n",
       "544     216      0  \n",
       "1838     75      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Democratic...\")\n",
    "top_dem = phrases_df.sort_values(by='bias_score', ascending=True).head(200).copy()\n",
    "top_dem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dem['n_senators'] =  top_dem.apply(lambda x: len(df[df.tweet.str.contains(x.phrase)].name.unique()),axis=1)\n",
    "top_dem = top_dem[top_dem.n_senators > 2]\n",
    "top_dem.head(50).to_csv('top_50_democrat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Republican:\n"
     ]
    }
   ],
   "source": [
    "print(\"Most Republican:\")\n",
    "top_rep = phrases_df.sort_values(by='bias_score', ascending=False).head(200).copy()\n",
    "top_rep['n_senators'] =  top_rep.apply(lambda x: len(df[df.tweet.str.contains(x.phrase)].name.unique()),axis=1)\n",
    "top_rep = top_rep[top_rep.n_senators > 2]\n",
    "top_rep.head(50).to_csv('top_50_republican.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
