{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n7mNJhSWwSZ2",
    "outputId": "9970d119-f64d-4e7a-8e31-8ae292f497f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "04a2VQrHv_Ix",
    "outputId": "9d525280-fcfb-4c9b-ebdc-ace3b3789cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=557e4e73a03b7483c5009f6be11e0b945bae4c7d7de847cd90d433e5169566f4\n",
      "  Stored in directory: c:\\users\\quynh\\appdata\\local\\pip\\cache\\wheels\\72\\b0\\3f\\1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gN9P29lzAsz3",
    "outputId": "aca93ce6-15ff-40f8-f05e-60e1634b90aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\quynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\quynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\quynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wjcRfFigJba"
   },
   "source": [
    "**Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jt4SLj5_GNPY"
   },
   "outputs": [],
   "source": [
    "def cleanup_Article(s):\n",
    "  #lower casing\n",
    "  s=s.lower()\n",
    "\n",
    "  #lemmatization\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens_2=[] \n",
    "  tokens = nltk.word_tokenize(s)\n",
    "  for token in tokens:\n",
    "    tokens_2.append(lemmatizer.lemmatize(token))\n",
    "\n",
    "  #stop word and punctuation removal\n",
    "  stop = stopwords.words('english') + list(string.punctuation) + [\"''\",\"``\",\"..\"]\n",
    "  cleanup = \" \".join(i for i in tokens_2 if i not in stop)\n",
    "  return cleanup\n",
    "\n",
    "def preprocess():\n",
    "  # reading datafile in a dataframe\n",
    "  #raw_data = pd.read_excel (r'/content/drive/My Drive/ir_project/data/Final_Data_Article_Annotation.xlsx')\n",
    "\n",
    "  #Pragya\n",
    "  # raw_data=pd.read_excel('/content/drive/My Drive/IR/Project/Project Final/without aap.xlsx')\n",
    "  raw_data = pd.read_excel('./Final_Data_Article_Annotation.xlsx')\n",
    "  article_list=[]\n",
    "  label_list=[]\n",
    "  for article,label in zip(raw_data.Article.iloc,raw_data.Annotation.iloc):    \n",
    "    article=cleanup_Article(article)\n",
    "    #print(article)\n",
    "    article_list.append(article)  \n",
    "    #print(lable)\n",
    "    label_list.append(label.upper())\n",
    "  list_of_tuples = list(zip(article_list, label_list))  \n",
    "  df = pd.DataFrame(list_of_tuples, columns = ['Article', 'label'])  \n",
    "  return df\n",
    "\n",
    "\n",
    "df=preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gy8WDTCBg3uT"
   },
   "source": [
    "**Plotting the data labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "iru7EG5FCczB",
    "outputId": "bc83c6a1-faad-4848-cbc9-58f272bfdafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NONE': 316, 'BJP': 287, 'CONGRESS': 176, 'AAP': 50})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "def plot_count(Y_data):\n",
    "  y=Counter(Y_data)\n",
    "  print(y)\n",
    "  sns.countplot(Y_data)\n",
    "\n",
    "\n",
    "plot_count(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oNRwCwqhLIO"
   },
   "source": [
    "**Splitting The DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03UTitc-EktL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,classification_report,accuracy_score\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['Article'],df['label'], test_size=0.25,random_state=42,stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7uhkZcThTCL"
   },
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUzacpqND4ZX"
   },
   "outputs": [],
   "source": [
    "\n",
    "# table dictionary will have class count for each term.\n",
    "class_label={'BJP':0,'CONGRESS':1,'AAP':2,'NONE':3}\n",
    "reverse_class_label={0:'BJP',1:'CONGRESS',2:'AAP',3:'NONE'} \n",
    "def table_creation(X_train,Y_train):\n",
    "  table={}             # will contain the article count of a term in a class\n",
    "  term_count_in_class={}         # will contain the term count in a class\n",
    "  class_doc_count=np.array([0,0,0,0])  # number of articles in a class\n",
    "  class_word_count=np.array([0,0,0,0]) # number of words in a class\n",
    "  class_count=np.array([0,0,0,0])\n",
    "\n",
    "  for article,label in zip(X_train,Y_train):\n",
    "    #print(article)\n",
    "    class_doc_count[class_label[label]]+=1\n",
    "    class_word_count[class_label[label]]+=len(article)\n",
    "    unique_tokens={-1}\n",
    "    for term in article.split():\n",
    "      #print(term)\n",
    "      #term count in of each term in each class\n",
    "      if term not in term_count_in_class:\n",
    "        term_count_in_class[term]=class_count.copy()\n",
    "      term_count_in_class[term][class_label[label]]+=1\n",
    "      unique_tokens.add(term)\n",
    "    \n",
    "    #print(\"unique tokens in article are\",unique_tokens)\n",
    "    unique_tokens.remove(-1) \n",
    "\n",
    "    for term in unique_tokens:\n",
    "      if term not in table:\n",
    "        table[term]=class_count.copy()\n",
    "      table[term][class_label[label]]+=1\n",
    "  \n",
    "  return table, class_word_count, class_doc_count, term_count_in_class\n",
    "table, class_word_count, class_doc_count, term_count_in_class=table_creation(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjtG9l_yhf0F"
   },
   "source": [
    "**Calculate Mutual Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dFIFtpG9KLDZ",
    "outputId": "ae1cd7bc-1000-4406-c9f0-b638e5862c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of articles are 621\n"
     ]
    }
   ],
   "source": [
    "#to calculate mutual information for each term in each class\n",
    "def cal_mutual_info(table,class_word_count,class_doc_count):\n",
    "  N=0\n",
    "  for i in class_doc_count:\n",
    "    N+=i\n",
    "  print(\"total number of articles are\",N)\n",
    "  mi_table=[[],[],[],[]]  # five list to contain the mutual information for each class \n",
    "  for term in table:\n",
    "      #print(\"calculating mi for \",term,\" \",table[term])\n",
    "      for class_ in range(0,4):\n",
    "          #print(\"for class \",class_)\n",
    "          n11=table[term][class_]         # term is present in class\n",
    "          n10=np.sum(table[term])-n11        # term is present but not in the class\n",
    "          n01=class_doc_count[class_]-n11   # number of docs in class not having term \n",
    "          n00=N-(n01+n10+n11)                  # number of docs neither term nor class\n",
    "          #print(\"n11,n10,n01,n00 \",n11,n10,n01,n00)\n",
    "          \n",
    "          if n11==0:\n",
    "              t1=0\n",
    "          else:\n",
    "              t1=(n11/N) * ((np.log(N)+np.log(n11)) - (np.log(n11+n01) + np.log(n11+n10)))\n",
    "          if n01==0:\n",
    "              t2=0\n",
    "          else:\n",
    "              t2=(n01/N) * ((np.log(N)+np.log(n01)) - (np.log(n01+n00) + np.log(n01+n11)))\n",
    "          if n10==0:\n",
    "              t3=0\n",
    "          else:\n",
    "              t3=(n10/N) * ((np.log(N)+np.log(n10)) - (np.log(n10+n11) + np.log(n10+n00)))\n",
    "          if n00==0:\n",
    "              t4=0\n",
    "          else:\n",
    "              t4=(n00/N) * ((np.log(N)+np.log(n00)) - (np.log(n00+n01) + np.log(n00+n10)))\n",
    "          m=t1+t2+t3+t4\n",
    "          mi_table[class_].append(m)\n",
    "  return mi_table\n",
    "mi_table=cal_mutual_info(table,class_word_count, class_doc_count)\n",
    "\n",
    "\n",
    "\n",
    "#creating word map, each word is assigned a uniuqe id like we did for each document\n",
    "def create_word_map(list_of_words):\n",
    "    word_forward_map={}\n",
    "    word_reverse_map={}\n",
    "    count=0\n",
    "    for word in list_of_words:\n",
    "        word_forward_map[word] = count\n",
    "        count = count + 1\n",
    "    word_reverse_map = {v: k for k, v in word_forward_map.items()}\n",
    "    return word_forward_map,word_reverse_map\n",
    "word_forward_map,word_reverse_map=create_word_map(table.keys())\n",
    "\n",
    "\n",
    "\n",
    "#this method will select feaures for each class and returns new vocabulary\n",
    "def feature_selection(mi_table,k,word_forward_map,word_reverse_map):\n",
    "    top_k_words=[]\n",
    "    for class_id in range(0,4):\n",
    "        temp = np.argsort(np.array(mi_table[class_id]))\n",
    "        temp = temp[::-1]\n",
    "        top_k_words.append(temp[:k].copy())\n",
    "    \n",
    "    new_vocab={-1}\n",
    "    count=0\n",
    "    for list_of_words in top_k_words:\n",
    "        #print(list_of_words)\n",
    "        #print(\"for class \",count,\" top \",k,\" words are\")\n",
    "        for wordid in list_of_words:\n",
    "            #print(word_reverse_map[wordid])\n",
    "            new_vocab.add(word_reverse_map[wordid])\n",
    "        count=count+1\n",
    "        \n",
    "    new_vocab.remove(-1)\n",
    "    #print(new_vocab)\n",
    "    return top_k_words,new_vocab\n",
    "\n",
    "top_k_words,new_vocab=feature_selection(mi_table,200,word_forward_map,word_reverse_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#to calculate term and class probability \n",
    "def calculate_probability(new_vocab,term_count_in_class,class_word_count,class_doc_count):\n",
    "    term_probability={}\n",
    "    beta=len(new_vocab)\n",
    "    for word in new_vocab:\n",
    "      #print(word)\n",
    "      term_probability[word]=[]\n",
    "      for class_id in range(0,4):\n",
    "        tot=class_word_count[class_id]\n",
    "        #print(\"word count in class\",tot)\n",
    "        tc=term_count_in_class[word][class_id]\n",
    "        p=(tc+1)/(tot+beta)  #add one smoothening\n",
    "        term_probability[word].append(p)    \n",
    "    class_probability=[]\n",
    "    N=np.sum(class_doc_count)\n",
    "    #print(N)\n",
    "    for doc_count in class_doc_count:\n",
    "        class_probability.append(doc_count/N)\n",
    "    return class_probability,term_probability\n",
    "class_probability,term_probability=calculate_probability(new_vocab,term_count_in_class,class_word_count,class_doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ttev2E4iMQz"
   },
   "source": [
    "**Naive Bayes With Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "CmsV0uisexK4",
    "outputId": "edbfd1a0-141b-46b3-9155-a53c4d0096b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[13  0  0  0]\n",
      " [17 46  6  3]\n",
      " [ 0  9 35  0]\n",
      " [12 14  4 49]]\n",
      "Accuracy Score : 0.6875\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AAP       0.31      1.00      0.47        13\n",
      "         BJP       0.67      0.64      0.65        72\n",
      "    CONGRESS       0.78      0.80      0.79        44\n",
      "        NONE       0.94      0.62      0.75        79\n",
      "\n",
      "    accuracy                           0.69       208\n",
      "   macro avg       0.67      0.76      0.66       208\n",
      "weighted avg       0.77      0.69      0.71       208\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naive_bayes(new_vocab,term_probability,class_probability,X_test):\n",
    "    y_predicted=[]\n",
    "    for article in X_test:\n",
    "        max_score=-math.inf\n",
    "        score=0\n",
    "        result_class=-1                          #initially document belonging to none class\n",
    "        for class_id in range(0,4):\n",
    "            score=np.log(class_probability[class_id])\n",
    "            for word in article.split():\n",
    "                if word in new_vocab:\n",
    "                    score=score+np.log(term_probability[word][class_id])\n",
    "            #print(\"docid \",docid,\" class \",class_id,\" score \",score)\n",
    "            if score>max_score:\n",
    "                max_score=score\n",
    "                result_class=class_id\n",
    "        #result[docid]=result_class\n",
    "        y_predicted.append(reverse_class_label[result_class])       \n",
    "    return y_predicted          \n",
    "\n",
    "y_predicted=naive_bayes(new_vocab,term_probability,class_probability,X_test)\n",
    "def performance(y_actual,y_predicted):\n",
    "    results = confusion_matrix(y_actual, y_predicted)   \n",
    "    print ('Confusion Matrix :')\n",
    "    print(results) \n",
    "    print ('Accuracy Score :',accuracy_score(y_actual, y_predicted) )\n",
    "    print ('Report : ')\n",
    "    print (classification_report(y_actual, y_predicted) )\n",
    "    return accuracy_score(y_actual, y_predicted)\n",
    "\n",
    "performance(Y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqumQlK9C4eM"
   },
   "source": [
    "**NaiiveBayes without Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "rmO8rNo4PoMx",
    "outputId": "d768ffcd-8c2e-418a-877b-9c0d915143d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5548285882062347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AAP       0.00      0.00      0.00        13\n",
      "         BJP       0.48      0.88      0.62        72\n",
      "    CONGRESS       1.00      0.11      0.20        44\n",
      "        NONE       0.82      0.75      0.78        79\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.58      0.43      0.40       208\n",
      "weighted avg       0.69      0.61      0.55       208\n",
      "\n",
      "0.6105769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quynh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "######NaiiveBayes without Feature Selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "Count=CountVectorizer()\n",
    "X_train_count=Count.fit_transform(X_train)\n",
    "X_test_count=Count.transform(X_test)\n",
    "\n",
    "Tf_idf=TfidfTransformer()\n",
    "X_train_tfidf=Tf_idf.fit_transform(X_train_count)\n",
    "X_test_tfidf=Tf_idf.transform(X_test_count)\n",
    "Classifier = MultinomialNB().fit(X_train_tfidf, Y_train)\n",
    "predicted = Classifier.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(f1_score(Y_test, predicted,average='weighted'))\n",
    "print(classification_report(Y_test,predicted))\n",
    "print(accuracy_score(Y_test,predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlTW-FE4ifyS"
   },
   "source": [
    "**SVM Without Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "_PrZppK50gcg",
    "outputId": "cdca3a7a-d9e7-42e3-a578-860e9ad50d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For unigrams--------------------\n",
      "[LibSVM]0.6870300043094161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AAP       1.00      0.08      0.14        13\n",
      "         BJP       0.65      0.79      0.71        72\n",
      "    CONGRESS       0.86      0.55      0.67        44\n",
      "        NONE       0.71      0.82      0.76        79\n",
      "\n",
      "    accuracy                           0.71       208\n",
      "   macro avg       0.80      0.56      0.57       208\n",
      "weighted avg       0.74      0.71      0.69       208\n",
      "\n",
      "0.7067307692307693\n",
      "For Bigrams----------------------\n",
      "[LibSVM]0.4298304865761734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AAP       0.00      0.00      0.00        13\n",
      "         BJP       0.60      0.49      0.54        72\n",
      "    CONGRESS       0.50      0.02      0.04        44\n",
      "        NONE       0.47      0.89      0.62        79\n",
      "\n",
      "    accuracy                           0.51       208\n",
      "   macro avg       0.39      0.35      0.30       208\n",
      "weighted avg       0.49      0.51      0.43       208\n",
      "\n",
      "0.5096153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quynh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SVM without feature Selection using different approaches:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# SVM with tf-idf\n",
    "#1. tf-idf using n grams\n",
    "#a) unigram\n",
    "print(\"For unigrams--------------------\")\n",
    "vector=TfidfVectorizer(analyzer='word',ngram_range=(1,1))\n",
    "X_train_vector=vector.fit_transform(X_train)\n",
    "X_test_vector=vector.transform(X_test)\n",
    "classifier=SVC(verbose=True).fit(X_train_vector,Y_train)\n",
    "predicted=classifier.predict(X_test_vector)\n",
    "print(f1_score(Y_test,predicted,average='weighted'))\n",
    "print(classification_report(Y_test,predicted))\n",
    "print(accuracy_score(Y_test,predicted))\n",
    "\n",
    "\n",
    "print(\"For Bigrams----------------------\")\n",
    "#b) bigram\n",
    "vector=TfidfVectorizer(analyzer='word',ngram_range=(2,2))\n",
    "X_train_vector=vector.fit_transform(X_train)\n",
    "X_test_vector=vector.transform(X_test)\n",
    "classifier=SVC(verbose=True).fit(X_train_vector,Y_train)\n",
    "predicted=classifier.predict(X_test_vector)\n",
    "print(f1_score(Y_test,predicted,average='weighted'))\n",
    "print(classification_report(Y_test,predicted))\n",
    "print(accuracy_score(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElUg5MTUi3n9"
   },
   "source": [
    "**SVM with Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Zu4f71Sg4rZC",
    "outputId": "458d0881-7b6a-446e-cad0-9d952448a9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.7609963453784965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AAP       0.83      0.38      0.53        13\n",
      "         BJP       0.71      0.79      0.75        72\n",
      "    CONGRESS       0.85      0.77      0.81        44\n",
      "        NONE       0.77      0.80      0.78        79\n",
      "\n",
      "    accuracy                           0.76       208\n",
      "   macro avg       0.79      0.69      0.72       208\n",
      "weighted avg       0.77      0.76      0.76       208\n",
      "\n",
      "0.7644230769230769\n"
     ]
    }
   ],
   "source": [
    "#SVM with feature selection\n",
    "def produce_count_vector(X_data,vocab,term_count_in_class):\n",
    "  data_count=[]\n",
    "  for index in X_data:\n",
    "    count_vector=[]\n",
    "    values=index.split(' ')\n",
    "    for word in vocab:\n",
    "      if word in values:\n",
    "        count_vector.append(values.count(word))\n",
    "      else:\n",
    "        count_vector.append(0)\n",
    "    data_count.append(count_vector)\n",
    "  return data_count\n",
    "\n",
    "X_train_count=produce_count_vector(X_train,new_vocab,term_count_in_class)\n",
    "X_test_count=produce_count_vector(X_test,new_vocab,term_count_in_class)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vector=TfidfTransformer()\n",
    "X_train_vector=vector.fit_transform(X_train_count)\n",
    "X_test_vector=vector.transform(X_test_count)\n",
    "classifier=SVC(verbose=True).fit(X_train_vector,Y_train)\n",
    "predicted=classifier.predict(X_test_vector)\n",
    "print(f1_score(Y_test,predicted,average='weighted'))\n",
    "print(classification_report(Y_test,predicted))\n",
    "print(accuracy_score(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IRProject_withoutaap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
